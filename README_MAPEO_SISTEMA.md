# MAPEO COMPLETO DEL SISTEMA DE SIMULACIÃ“N
## Flujo de EjecuciÃ³n End-to-End con Nombres de Funciones

> **DocumentaciÃ³n TÃ©cnica Completa**  
> Sistema de simulaciÃ³n de detectabilidad de supernovas  
> Pipeline desde CLI hasta resultados cientÃ­ficos finales

---

## ğŸ“‹ **RESUMEN EJECUTIVO - FLUJO COMPLETO**

### **ğŸ¯ Pipeline End-to-End en 5 Niveles:**

**1. ENTRADA CLI** â†’ **2. CONFIGURACIÃ“N** â†’ **3. MUESTREO CIENTÃFICO** â†’ **4. PIPELINE FÃSICO** â†’ **5. AGREGACIÃ“N ESTADÃSTICA**

### **ğŸ” Secuencia Detallada de EjecuciÃ³n:**

1. **`simple_runner.py`** inicia el sistema:
   - **Importa funciones**: `create_simple_config()` desde el archivo `simple_config.py`
   - **FunciÃ³n `create_simple_config()`**: Retorna un objeto de clase `SimpleConfig` con parÃ¡metros validados
   - **Ejecuta `main()` [simple_runner.py]**: Entry point principal del sistema
     - **`parse_arguments()` [SE EJECUTA DENTRO DE main()]**: Parsea argumentos CLI
     - **`setup_environment()` [SE EJECUTA DENTRO DE main()]**: **CREA CARPETAS** para preparar las salidas en `outputs/` (single_runs/, batch_runs/, logs/, etc.)
     - **`run_custom_batch()` [SE EJECUTA DENTRO DE main()]**: Recibe inputs de los parÃ¡metros de lÃ­nea de comandos parseados

2. **TransiciÃ³n a Batch Runner:**
   - **Dentro de `run_custom_batch()` [simple_runner.py]**: Se crea la config con `create_simple_config()` usando parÃ¡metros CLI
   - **Con la config creada [DENTRO DE run_custom_batch()]**: Se ejecuta `run_scientific_batch(config)` 
   - **Se transfiere control**: Del archivo `simple_runner.py` al archivo `batch_runner.py`
   - **`run_scientific_batch()` [batch_runner.py]**: FunciÃ³n wrapper que instancia `ProfessionalBatchRunner()` 
     - **`run_batch()` [SE EJECUTA DENTRO DE run_scientific_batch()]**: MÃ©todo principal del batch runner

3. **GeneraciÃ³n de ParÃ¡metros CientÃ­ficos**:
   - **`run_batch()` [ProfessionalBatchRunner]**: Loop principal de iteraciones
     - **`create_run_parameters()` [SE EJECUTA DENTRO DE run_batch()]**: Muestreo cientÃ­fico por iteraciÃ³n
       - **`sample_cosmological_redshift()` [SE EJECUTA DENTRO DE create_run_parameters()]**: Muestreo cosmolÃ³gico volume-weighted
       - **`sample_extinction_by_type()` [SE EJECUTA DENTRO DE create_run_parameters()]**: Distribuciones acadÃ©micas por tipo SN
       - **`get_sn_templates()` [SE EJECUTA DENTRO DE create_run_parameters()]**: Obtiene templates disponibles
       - **`np.random.choice(available_templates)` [SE EJECUTA DENTRO DE create_run_parameters()]**: SelecciÃ³n **ALEATORIA** del template
       - **`sample_realistic_mw_extinction()` [SE EJECUTA DENTRO DE create_run_parameters()]**: ExtinciÃ³n MW que llama **INTERNAMENTE**:
         - Muestrear coordenadas de ZTF (actualmente sintÃ©ticas)
         - Consultar mapas de extinciÃ³n realistas SFD98
         - **NOTA FUTURA**: No usa coordenadas reales del objeto ZTF pero serÃ­a bueno implementarlo
   - **Resultado**: Finalmente tenemos **TODOS** los parÃ¡metros guardados en `iteration_params`

4. **EjecuciÃ³n Individual**:
   - **`execute_single_run()` [SE EJECUTA DENTRO DE run_batch()]**: Recibe `iteration_params`
     - **`update_config_for_run()` [SE EJECUTA DENTRO DE execute_single_run()]**: **ACTUALIZA** los parÃ¡metros de `config.py` global
     - **`load_and_validate_config()` [SE EJECUTA DENTRO DE execute_single_run()]**: Confirma que no haya errores en configuraciÃ³n
     - **`import main` [SE EJECUTA DENTRO DE execute_single_run()]**: Importa el mÃ³dulo main.py
     - **`main.main(config=validated_config)` [SE EJECUTA DENTRO DE execute_single_run()]**: Llamada al pipeline cientÃ­fico

5. **Pipeline CientÃ­fico Completo** (en `main.py` viene TODO el pipeline de proyecciÃ³n):
   - **`main()` [main.py]**: FunciÃ³n principal del pipeline cientÃ­fico
     - **PASO 1 [SE EJECUTA DENTRO DE main()]**: **LEE LOS ESPECTROS**
       - **`leer_spec()` [SE EJECUTA EN PASO 1]**: Lee archivo de template seleccionado
     - **PASO 2 [SE EJECUTA DENTRO DE main()]**: **APLICA CORRECCIONES COSMOLÃ“GICAS**
       - **`correct_redeening()` [SE EJECUTA EN PASO 2]**: Aplica redshift + extinciÃ³n fÃ­sica
     - **PASO 3 [SE EJECUTA DENTRO DE main()]**: **CARGA RESPUESTA DE FILTRO**
       - **`pd.read_csv(path_response)` [SE EJECUTA EN PASO 3]**: Carga curva respuesta fotomÃ©trica
     - **PASO 4 [SE EJECUTA DENTRO DE main()]**: **FOTOMETRÃA SINTÃ‰TICA**
       - **`Syntetic_photometry_v2()` [SE EJECUTA EN PASO 4]**: Overlap 95% entre espectro y filtro
     - **PASO 5 [SE EJECUTA DENTRO DE main()]**: **SUAVIZADO LOESS**
       - **`Loess_fit()` [SE EJECUTA EN PASO 5]**: InterpolaciÃ³n estadÃ­stica de curva de luz
     - **PASO 6 [SE EJECUTA DENTRO DE main()]**: **CALIBRACIÃ“N FOTOMÃ‰TRICA**
       - **ConversiÃ³n flujo â†’ magnitudes [SE EJECUTA EN PASO 6]**: Usando constantes de punto cero
     - **PASO 7 [SE EJECUTA DENTRO DE main()]**: **RUIDO FOTOMÃ‰TRICO**
       - **`np.random.normal()` [SE EJECUTA EN PASO 7]**: Simula Poisson + Gaussiana
     - **PASO 7.5 [SE EJECUTA DENTRO DE main()]**: **CONVERSIÃ“N TEMPORAL CRÃTICA**
       - **`maximo_lc()` [SE EJECUTA EN PASO 7.5]**: Obtiene MJD del mÃ¡ximo
       - **ConversiÃ³n fases â†’ MJD [SE EJECUTA EN PASO 7.5]**: Para SNe core-collapse

6. **âš ï¸ Bug Temporal Resuelto** (Paso 7.5 - DETALLES COMPLETOS):
   ```python
   # DATOS DE ENTRADA (antes del PASO 7.5):
   fases = [-10, 0, +20]     # â† Fases relativas (dÃ­as respecto al mÃ¡ximo)
   maximum = 53671           # â† MJD absoluto del mÃ¡ximo (funciÃ³n maximo_lc)
   mjd_pivote = 59000       # â† MJD de observaciones modernas ZTF

   # CÃLCULO ERRÃ“NEO:
   desplazamiento = 59000 - 53671 + offset â‰ˆ 5329 dÃ­as
   fases_ajustadas = [-10 + 5329, 0 + 5329, +20 + 5329]
                   = [5319, 5329, 5349]  # â† Â¡Fechas imposibles aÃ±o 1846!
   
   # SOLUCIÃ“N: ConversiÃ³n explÃ­cita antes de proyecciÃ³n
   if tipo in ['Ibc', 'Ib', 'Ic']:
       mjd_absolute = maximum + lc_df['fase']  # Fases â†’ MJD absoluto
       lc_df['fase'] = mjd_absolute           # Actualizar DataFrame
   ```

     - **PASO 8 [SE EJECUTA DENTRO DE main()]**: **PROYECCIÃ“N TEMPORAL**
       - **`field_projection()` [SE EJECUTA EN PASO 8]**: ProyecciÃ³n sobre observaciones reales del survey
         - **`maximo_lc()` [SE EJECUTA DENTRO DE field_projection()]**: Calcula mÃ¡ximo de la SN
         - **`interpolate.interp1d()` [SE EJECUTA DENTRO DE field_projection()]**: Interpola magnitudes en tiempos observaciÃ³n
     - **PASO 9 [SE EJECUTA DENTRO DE main()]**: **RESUMEN CON MÃ‰TRICAS**
       - **CÃ¡lculo detecciones/upper limits [SE EJECUTA EN PASO 9]**: AnÃ¡lisis de detectabilidad
     - **PASO 10 [SE EJECUTA DENTRO DE main()]**: **GUARDAR RESULTADOS**
       - **`save_projection_results()` [SE EJECUTA EN PASO 10]**: Persistencia individual
     - **PASO 11 [SE EJECUTA DENTRO DE main()]**: **ACTUALIZAR ÃNDICE**
       - **`create_master_index()` [SE EJECUTA EN PASO 11]**: ActualizaciÃ³n Ã­ndice maestro

7. **Lo que pasa DESPUÃ‰S de main** (retorno y extracciÃ³n de resultados):
   - **RETORNO A `execute_single_run()` [batch_runner.py]**: DespuÃ©s de completar main.main()
     - **`extract_run_statistics()` [SE EJECUTA DENTRO DE execute_single_run()]**: Busca CSV generado por `save_projection_results()`
       - **`glob.glob()` [SE EJECUTA DENTRO DE extract_run_statistics()]**: Busca archivos summary mÃ¡s recientes
       - **`pd.read_csv()` [SE EJECUTA DENTRO DE extract_run_statistics()]**: Lee mÃ©tricas reales del CSV
     - **Retorna estadÃ­sticas confirmadas [DESDE execute_single_run()]**: No estimadas, sino valores reales
     - **Timing de ejecuciÃ³n [EN execute_single_run()]**: Se calcula tiempo total de la iteraciÃ³n

8. **AgregaciÃ³n por Batch** (retorno a `run_batch()`):
   - **RETORNO A `run_batch()` [ProfessionalBatchRunner]**: DespuÃ©s de execute_single_run()
     - **`add_successful_run()` [SE EJECUTA DENTRO DE run_batch()]**: Acumula estadÃ­sticas globales
       - **Suma detecciones totales [DENTRO DE add_successful_run()]**: AcumulaciÃ³n estadÃ­stica
       - **Actualiza distribuciones por tipo [DENTRO DE add_successful_run()]**: Para anÃ¡lisis cientÃ­fico
     - **Registro en `run_registry` [DENTRO DE run_batch()]**: Lista completa con TODAS las iteraciones

9. **Persistencia Final**:
   - **AL FINAL DE `run_batch()` [ProfessionalBatchRunner]**: DespuÃ©s del loop de iteraciones
     - **`save_batch_results()` [SE EJECUTA DENTRO DE run_batch()]**: Guardado agregado final
       - **`json.dump(batch_metadata)` [SE EJECUTA DENTRO DE save_batch_results()]**: Guarda configuraciÃ³n completa
       - **`df_runs.to_csv()` [SE EJECUTA DENTRO DE save_batch_results()]**: CSV con todas las iteraciones
       - **GeneraciÃ³n de reportes [DENTRO DE save_batch_results()]**: Archivos de resumen estadÃ­stico

### **ğŸ¯ Resultado Final:**
- **Simulaciones individuales** con reproducibilidad total
- **EstadÃ­sticas agregadas** publication-ready
- **Trazabilidad completa** desde CLI hasta mÃ©tricas cientÃ­ficas
- **Sistema robusto** con fallbacks y validaciÃ³n en cada nivel

---

## ï¿½ **MAPEO JERÃRQUICO COMPLETO DE FUNCIONES**

### **ğŸ“‹ Mapeo EspecÃ­fico de Funciones por Archivo**

#### **`simple_runner.py`** - Entry Point y Control CLI
```python
main()                           # Entry point principal del sistema
â”œâ”€â”€ parse_arguments()            # [EJECUTA DENTRO DE main()]
â”œâ”€â”€ setup_environment()          # [EJECUTA DENTRO DE main()] - Crea estructura de carpetas
â””â”€â”€ run_custom_batch()           # [EJECUTA DENTRO DE main()] - Coordina ejecuciÃ³n batch
    â”œâ”€â”€ create_simple_config()   # [EJECUTA DENTRO DE run_custom_batch()]
    â””â”€â”€ run_scientific_batch()   # [EJECUTA DENTRO DE run_custom_batch()]
```

#### **`batch_runner.py`** - CoordinaciÃ³n de Batch y Muestreo CientÃ­fico
```python
run_scientific_batch(config)                           # Wrapper function
â””â”€â”€ ProfessionalBatchRunner.run_batch()                # [EJECUTA DENTRO DE run_scientific_batch()]
    â”œâ”€â”€ create_run_parameters()                        # [EJECUTA DENTRO DE run_batch()]
    â”‚   â”œâ”€â”€ sample_cosmological_redshift()             # [EJECUTA DENTRO DE create_run_parameters()]
    â”‚   â”œâ”€â”€ sample_extinction_by_type()                # [EJECUTA DENTRO DE create_run_parameters()]  
    â”‚   â”œâ”€â”€ get_sn_templates()                         # [EJECUTA DENTRO DE create_run_parameters()]
    â”‚   â”œâ”€â”€ np.random.choice(available_templates)      # [EJECUTA DENTRO DE create_run_parameters()]
    â”‚   â””â”€â”€ sample_realistic_mw_extinction()           # [EJECUTA DENTRO DE create_run_parameters()]
    â”‚       â”œâ”€â”€ sample_ztf_coordinates()               # [EJECUTA DENTRO DE sample_realistic_mw_extinction()]
    â”‚       â””â”€â”€ query_sfd98_extinction_maps()          # [EJECUTA DENTRO DE sample_realistic_mw_extinction()]
    â”œâ”€â”€ execute_single_run(iteration_params)           # [EJECUTA DENTRO DE run_batch()]
    â”‚   â”œâ”€â”€ update_config_for_run()                    # [EJECUTA DENTRO DE execute_single_run()]
    â”‚   â”œâ”€â”€ load_and_validate_config()                 # [EJECUTA DENTRO DE execute_single_run()]
    â”‚   â”œâ”€â”€ main.main(config=validated_config)         # [EJECUTA DENTRO DE execute_single_run()]
    â”‚   â””â”€â”€ extract_run_statistics()                   # [EJECUTA DENTRO DE execute_single_run()]
    â”‚       â”œâ”€â”€ glob.glob()                            # [EJECUTA DENTRO DE extract_run_statistics()]
    â”‚       â””â”€â”€ pd.read_csv()                          # [EJECUTA DENTRO DE extract_run_statistics()]
    â”œâ”€â”€ add_successful_run()                           # [EJECUTA DENTRO DE run_batch()]
    â”‚   â”œâ”€â”€ accumulate_detection_stats()               # [EJECUTA DENTRO DE add_successful_run()]
    â”‚   â””â”€â”€ update_type_distributions()                # [EJECUTA DENTRO DE add_successful_run()]
    â””â”€â”€ save_batch_results()                           # [EJECUTA DENTRO DE run_batch()]
        â”œâ”€â”€ json.dump(batch_metadata)                  # [EJECUTA DENTRO DE save_batch_results()]
        â”œâ”€â”€ df_runs.to_csv()                           # [EJECUTA DENTRO DE save_batch_results()]
        â””â”€â”€ generate_summary_reports()                 # [EJECUTA DENTRO DE save_batch_results()]
```

#### **`main.py`** - Pipeline CientÃ­fico (11 Pasos)
```python
main(config)                                          # Pipeline cientÃ­fico principal
â”œâ”€â”€ PASO 1: leer_spec()                               # [EJECUTA DENTRO DE main()]
â”œâ”€â”€ PASO 2: correct_redeening()                       # [EJECUTA DENTRO DE main()]
â”œâ”€â”€ PASO 3: pd.read_csv(path_response)                # [EJECUTA DENTRO DE main()]
â”œâ”€â”€ PASO 4: Syntetic_photometry_v2()                  # [EJECUTA DENTRO DE main()]
â”œâ”€â”€ PASO 5: Loess_fit()                               # [EJECUTA DENTRO DE main()]
â”œâ”€â”€ PASO 6: flujo_to_magnitudes()                     # [EJECUTA DENTRO DE main()]
â”œâ”€â”€ PASO 7: np.random.normal()                        # [EJECUTA DENTRO DE main()]
â”œâ”€â”€ PASO 7.5: temporal_conversion_critical()          # [EJECUTA DENTRO DE main()]
â”‚   â”œâ”€â”€ maximo_lc()                                   # [EJECUTA DENTRO DE temporal_conversion_critical()]
â”‚   â””â”€â”€ phase_to_mjd_conversion()                     # [EJECUTA DENTRO DE temporal_conversion_critical()]
â”œâ”€â”€ PASO 8: field_projection()                        # [EJECUTA DENTRO DE main()]
â”‚   â”œâ”€â”€ maximo_lc()                                   # [EJECUTA DENTRO DE field_projection()]
â”‚   â””â”€â”€ interpolate.interp1d()                        # [EJECUTA DENTRO DE field_projection()]
â”œâ”€â”€ PASO 9: calculate_detection_metrics()             # [EJECUTA DENTRO DE main()]
â”œâ”€â”€ PASO 10: save_projection_results()                # [EJECUTA DENTRO DE main()]
â””â”€â”€ PASO 11: create_master_index()                    # [EJECUTA DENTRO DE main()]
```

#### **`core/correction.py`** - Funciones de CorrecciÃ³n FÃ­sica
```python
correct_redeening()                                   # Correcciones cosmolÃ³gicas principales
â”œâ”€â”€ apply_redshift_correction()                       # [EJECUTA DENTRO DE correct_redeening()]
â”œâ”€â”€ apply_host_extinction()                           # [EJECUTA DENTRO DE correct_redeening()]
â””â”€â”€ apply_mw_extinction()                             # [EJECUTA DENTRO DE correct_redeening()]
```

#### **`core/utils.py`** - Utilidades y ProyecciÃ³n
```python
field_projection()                                    # ProyecciÃ³n temporal sobre observaciones
â”œâ”€â”€ load_ztf_observations()                          # [EJECUTA DENTRO DE field_projection()]
â”œâ”€â”€ maximo_lc()                                       # [EJECUTA DENTRO DE field_projection()]
â”œâ”€â”€ interpolate_magnitudes()                          # [EJECUTA DENTRO DE field_projection()]
â””â”€â”€ calculate_detectability()                         # [EJECUTA DENTRO DE field_projection()]

save_projection_results()                             # Persistencia de resultados
â”œâ”€â”€ generate_csv_summary()                            # [EJECUTA DENTRO DE save_projection_results()]
â”œâ”€â”€ save_lightcurve_data()                            # [EJECUTA DENTRO DE save_projection_results()]
â””â”€â”€ update_run_metadata()                             # [EJECUTA DENTRO DE save_projection_results()]
```

---

## ï¿½ğŸš€ **PUNTO DE ENTRADA: simple_runner.py**

### **FunciÃ³n Principal: `main()`**
```python
def main():
    args = parse_arguments()  # Parsear CLI arguments
    setup_environment()       # Crear directorios de output
    run_custom_batch(...)     # Ejecutar batch con parÃ¡metros CLI
```

### **CLI Arguments â†’ SimpleConfig**
```python
def run_custom_batch(n_runs, redshift_max, sn_types, survey, filter_band, seed):
    # 1. CREAR CONFIGURACIÃ“N desde CLI
    config = create_simple_config(
        n_runs=n_runs,           # --runs 50
        redshift_max=redshift_max, # --redshift-max 0.3
        sn_types=sn_types,       # --sn-types Ia Ibc
        survey=survey,           # --survey ZTF
        filter_band=filter_band, # --filter r
        base_seed=seed           # --seed 123
    )
    
    # 2. EJECUTAR BATCH CIENTÃFICO
    results = run_scientific_batch(config)  # â†’ batch_runner.py
```

**Archivos Involucrados:**
- `simple_runner.py`: Entry point y CLI parsing
- `simple_config.py`: Clase `SimpleConfig` y funciÃ³n `create_simple_config()`

---

## ğŸ”„ **BATCH RUNNER: batch_runner.py**

### **FunciÃ³n de Alto Nivel: `run_scientific_batch(config)`**
```python
def run_scientific_batch(batch_config) -> Dict:
    runner = ProfessionalBatchRunner()
    return runner.run_batch(batch_config)  # â† MÃ©todo principal
```

### **Clase Principal: `ProfessionalBatchRunner`**

#### **MÃ©todo Central: `run_batch(batch_config)`**
```python
def run_batch(self, batch_config) -> Dict:
    self.stats.start_batch()  # Iniciar cronÃ³metro
    
    for i in range(batch_config.n_runs):  # Loop principal de iteraciones
        # 1. GENERAR PARÃMETROS de la iteraciÃ³n
        iteration_params = self.create_run_parameters(batch_config, i, batch_config.n_runs)
        
        # 2. EJECUTAR iteraciÃ³n individual
        success, iteration_results = self.execute_single_run(iteration_params)
        
        # 3. REGISTRAR resultados
        iteration_record = {**iteration_params, **iteration_results, 'success': success}
        self.run_registry.append(iteration_record)
        
        # 4. ACTUALIZAR estadÃ­sticas agregadas
        if success:
            self.stats.add_successful_run(...)
        else:
            self.stats.add_failed_run(...)
    
    # 5. GUARDAR resultados del batch
    self.save_batch_results(batch_config)
    return summary
```

---

## ğŸ“Š **GENERACIÃ“N DE PARÃMETROS: `create_run_parameters()`**

### **Muestreo CientÃ­fico por IteraciÃ³n**
```python
def create_run_parameters(self, batch_config, run_index: int, total_runs: int) -> Dict:
    np.random.seed(batch_config.base_seed + run_index)  # Reproducibilidad
    
    # 1. SELECCIONAR tipo de SN segÃºn distribuciÃ³n
    sn_type = np.random.choice(
        list(batch_config.sn_type_distribution.keys()),
        p=list(batch_config.sn_type_distribution.values())
    )  # â†’ "Ia", "Ibc", "II"
    
    # 2. MUESTREO COSMOLÃ“GICO (volume-weighted)
    redshift_sample = sample_cosmological_redshift(
        n_samples=1,
        z_min=z_min, z_max=z_max,
        H0=cosmology.get('H0', 70),
        Om=cosmology.get('Om', 0.3),
        OL=cosmology.get('OL', 0.7)
    )[0]  # â†’ 0.0249
    
    # 3. EXTINCIÃ“N DEL HOST (distribuciones por tipo)
    ebmv_host_sample = sample_extinction_by_type(
        sn_type=sn_type, 
        n_samples=1, 
        random_state=batch_config.base_seed + run_index
    )  # â†’ 0.043 (distribuciÃ³n exponencial/mixta segÃºn tipo)
    
    # 4. SELECCIONAR TEMPLATE aleatoriamente
    available_templates = get_sn_templates()[sn_type]
    template = np.random.choice(available_templates)  # â†’ "SN2006ep.dat"
    
    # 5. EXTINCIÃ“N MW (mapas realistas ZTF)
    ebmv_mw_sample = sample_realistic_mw_extinction(
        sn_name=template.replace('.dat', ''), 
        n_samples=1, 
        random_state=batch_config.base_seed + run_index
    )  # â†’ 0.067 (consulta mapas SFD98)
    
    # 6. SELECCIONAR SURVEY
    survey = np.random.choice(
        list(batch_config.survey_distribution.keys()),
        p=list(batch_config.survey_distribution.values())
    )  # â†’ "ZTF"
    
    return iteration_params  # Diccionario con todos los parÃ¡metros
```

**Funciones CientÃ­ficas Llamadas:**
- `sample_cosmological_redshift()` â†’ `core/correction.py`
- `sample_extinction_by_type()` â†’ `core/correction.py`
- `get_sn_templates()` â†’ `simple_config.py`
- `sample_realistic_mw_extinction()` â†’ `dust_maps.py`

---

## âš™ï¸ **EJECUCIÃ“N INDIVIDUAL: `execute_single_run()`**

### **Sistema Robusto con Fallback**
```python
def execute_single_run(self, iteration_params: Dict) -> Tuple[bool, Dict]:
    iteration_start_time = time.time()
    
    try:
        # 1. ACTUALIZAR configuraciÃ³n global
        self.update_config_for_run(iteration_params)
        
        # 2. VALIDAR configuraciÃ³n
        validated_config = load_and_validate_config()
        
        # 3. MÃ‰TODO PRIMARIO: EjecuciÃ³n directa
        try:
            import main
            main.main(config=validated_config)  # â† LLAMADA A MAIN.PY
            
            # Extraer estadÃ­sticas reales del CSV generado
            real_stats = self.extract_run_statistics(iteration_params)
            return True, iteration_stats
            
        except Exception as direct_error:
            # 4. MÃ‰TODO FALLBACK: Subprocess
            result = subprocess.run([sys.executable, 'main.py'], 
                                  capture_output=True, text=True)
            
            if result.returncode == 0:
                real_stats = self.extract_run_statistics(iteration_params)
                return True, iteration_stats
            else:
                return False, error_details
    
    except Exception as e:
        return False, {'error': str(e)}
```

### **ActualizaciÃ³n de ConfiguraciÃ³n: `update_config_for_run()`**
```python
def update_config_for_run(self, iteration_params: Dict) -> None:
    # MODIFICAR variables globales en config.py
    config.SN_CONFIG['sn_name'] = iteration_params['sn_name']        # "SN2006ep"
    config.SN_CONFIG['tipo'] = iteration_params['sn_type']           # "Ibc"
    config.SN_CONFIG['z_proy'] = iteration_params['redshift']        # 0.0249
    config.SN_CONFIG['ebmv_host'] = iteration_params['ebmv_host']    # 0.043
    config.SN_CONFIG['ebmv_mw'] = iteration_params['ebmv_mw']        # 0.067
    config.PATHS['spec_file'] = iteration_params['template_file']    # "Ibc/SN2006ep.dat"
    config.SN_CONFIG['selected_filter'] = iteration_params['filter_band']  # "r"
    config.SURVEY = iteration_params['survey']                       # "ZTF"
```

---

## ğŸ”¬ **PIPELINE CIENTÃFICO: main.py**

### **FunciÃ³n Principal: `main(config=None)`**
```python
def main(config=None):
    # CONFIGURACIÃ“N (si no viene del batch)
    if config is None:
        config = load_and_validate_config()
    
    # Extraer informaciÃ³n especÃ­fica
    survey_info = get_survey_info(config)
    sn_info = get_sn_info(config)
    processing_config = config['processing']
    extinction_config = config['extinction']
```

### **PASO 1: Lectura de Espectro**
```python
print(f"\nPASO 1: Lectura de espectro")
ESPECTRO, fases = leer_spec(path_spec, ot=False, as_pandas=True)
# â†’ Lista de DataFrames con espectros por fase
# â†’ Lista de fases temporales (MJD o dÃ­as relativos)
```

### **PASO 2: Correcciones CosmolÃ³gicas y ExtinciÃ³n**
```python
print(f"\nPASO 2: Correcciones cosmolÃ³gicas y extinciÃ³n")
ESPECTRO_corr, fases_corr = correct_redeening(
    sn=sn_name, ESPECTRO=ESPECTRO, fases=fases,
    z=z_proy,                    # Redshift de la iteraciÃ³n
    ebmv_host=ebmv_host_final,   # ExtinciÃ³n del host
    ebmv_mw=ebmv_mw,            # ExtinciÃ³n MW
    reverse=True, use_DL=True
)
# â†’ Aplica redshift cosmolÃ³gico + extinciÃ³n en orden fÃ­sico correcto
```

### **PASO 3: Curva de Respuesta del Filtro**
```python
print(f"\nPASO 3: Curva de respuesta del filtro {selected_filter}")
response_df = pd.read_csv(path_response, sep='\s+', comment='#', header=None)
response_df.columns = ['wave', 'response']
# â†’ Carga curva de respuesta del filtro fotomÃ©trico (r, g, i, etc.)
```

### **PASO 4: FotometrÃ­a SintÃ©tica**
```python
print(f"\nPASO 4: FotometrÃ­a sintÃ©tica")
for spec, fase in zip(ESPECTRO_corr, fases_corr):
    flux, porcentaje = Syntetic_photometry_v2(
        spec['wave'].values, spec['flux'].values,
        response_df['wave'].values, response_df['response'].values
    )
    if porcentaje > processing_config['overlap_threshold']:  # 0.95
        fases_lc.append(fase)
        fluxes_lc.append(flux)
# â†’ Convoluciona espectros con filtro segÃºn overlap mÃ­nimo
```

### **PASO 5: Suavizado LOESS**
```python
print(f"\nPASO 5: Suavizado LOESS")
df_loess = Loess_fit(LC_df, selected_filter, 
                    alpha=alpha_usado, plot=False)
# â†’ Suavizado estadÃ­stico para interpolar curva de luz
```

### **PASO 6: CalibraciÃ³n FotomÃ©trica**
```python
print(f"\nPASO 6: CalibraciÃ³n fotomÃ©trica")
constante = 'cte' + selected_filter  # cter, cteg, cteV, etc.
mul = arr_val_ctes[jj]              # Constante de punto cero
flux_calibrado = np.array(lc_df['flux']) / mul
mag = -2.5 * np.log10(np.clip(flux_calibrado, 1e-20, None))
# â†’ Convierte flujos a magnitudes calibradas
```

### **PASO 7: Ruido FotomÃ©trico**
```python
print(f"\nPASO 7: AplicaciÃ³n de ruido fotomÃ©trico")
noise_level = processing_config['noise_level']  # 0.15 (15%)
flux_noisy_norm = np.random.normal(
    loc=flux_norm, 
    scale=np.sqrt(np.abs(flux_norm)) * noise_level
)
mag_noisy = -2.5 * np.log10(flux_noisy)
# â†’ Simula ruido de Poisson con distribuciÃ³n gaussiana
```

### **PASO 7.5: ConversiÃ³n de Unidades Temporales (CRÃTICO)**
```python
maximum = maximo_lc(tipo, sn_name)  # MJD del mÃ¡ximo
if tipo in ['Ibc', 'Ib', 'Ic']:     # SNe core-collapse
    mjd_absolute = maximum + lc_df['fase']  # Fases relativas â†’ MJD absoluto
    lc_df['fase'] = mjd_absolute            # Actualizar DataFrame
```

**âš ï¸ BUG CRÃTICO RESUELTO:**
```python
# ANTES (INCORRECTO):
# fases = [-10, 0, +20]        # â† Fases relativas
# maximum = 53671              # â† MJD absoluto  
# mjd_pivote = 59000          # â† MJD modernas ZTF
# desplazamiento = 59000 - 53671 + offset â‰ˆ 5329 dÃ­as
# fases_ajustadas = [5319, 5329, 5349]  # â† Â¡Fechas imposibles aÃ±o 1846!

# DESPUÃ‰S (CORRECTO):
# fases_convertidas = [53659, 53671, 53691]  # â† MJD absoluto
# fases_ajustadas = [58988, 59000, 59089]    # â† Fechas modernas vÃ¡lidas
```

### **PASO 8: ProyecciÃ³n sobre Observaciones Reales**
```python
print(f"\nPASO 8: ProyecciÃ³n sobre observaciones reales ({SURVEY})")
df_obslog_survey = pd.read_csv(path_obslog)

# SelecciÃ³n de target especÃ­fica
if SURVEY == "ZTF":
    available_targets = df_obslog_survey[target_column].unique()
    selected_target = np.random.choice(available_targets)  # OID aleatorio

df_projected = field_projection(
    fases=lc_df['fase'].values,          # MJD absoluto (ya convertido)
    flux_y=mag_noisy,                    # Magnitudes con ruido
    df_obslog=df_obslog_survey,          # Observaciones reales del survey
    tipo=tipo,                           # Tipo SN para calcular mÃ¡ximo
    selected_filter=projection_filter,   # Filtro especÃ­fico del survey
    selected_field=selected_target,      # Target seleccionado
    offset=np.arange(offset_range[0], offset_range[1], offset_step),
    sn=sn_name,
    plot=show_debug_plots
)
```

### **FunciÃ³n `field_projection()` (core/projection.py):**
```python
def field_projection(fases, flux_y, df_obslog, tipo, selected_filter, 
                    offset, sn, selected_field=None, plot=False):
    # 1. FILTRAR observaciones por campo/OID y filtro
    df_filtered = obs_log[
        (obs_log['field/oid'] == selected_field) &
        (obs_log['filter'] == selected_filter)
    ]
    
    # 2. CALCULAR mÃ¡ximo de la SN
    maximum = maximo_lc(tipo, sn)
    
    # 3. SELECCIONAR offset aleatorio y calcular desplazamiento
    select_offset = np.random.choice(offset)
    mjd_pivote = df_filtered.iloc[0]['mjd']
    desplazamiento = mjd_pivote - maximum + select_offset
    
    # 4. AJUSTAR fases de la SN al tiempo de observaciÃ³n
    fases_ajustadas = [fecha + desplazamiento for fecha in fases]
    
    # 5. FILTRAR observaciones que coinciden temporalmente
    df_filtered_cut = df_filtered[
        (df_filtered['mjd'] >= min(fases_ajustadas)) &
        (df_filtered['mjd'] <= max(fases_ajustadas))
    ]
    
    # 6. INTERPOLAR magnitudes de la SN en tiempos de observaciÃ³n
    interpolation_function = interpolate.interp1d(
        fases_ajustadas, flux_y, kind='linear', fill_value='extrapolate'
    )
    df_filtered_cut['magnitud_proyectada'] = interpolation_function(df_filtered_cut['mjd'])
    
    # 7. CLASIFICAR detecciones vs upper limits
    df_filtered_cut['upperlimit'] = (
        df_filtered_cut['maglimit'] == df_filtered_cut['magnitud_proyectada']
    ).map({True: 'T', False: 'F'})
    
    return df_filtered_cut  # DataFrame con proyecciones finales
```

### **PASO 9: Resultados Finales**
```python
print(f"\nPASO 9: Resultados finales ({SURVEY})")
if len(df_projected) > 0:
    detecciones = len(df_projected[df_projected['upperlimit'] == 'F'])
    upper_limits = len(df_projected[df_projected['upperlimit'] == 'T'])
    tasa_deteccion = detecciones/len(df_projected)*100
    
    print(f"   â€¢ Detecciones: {detecciones:,}")
    print(f"   â€¢ Upper limits: {upper_limits:,}")
    print(f"   â€¢ Tasa de detecciÃ³n: {tasa_deteccion:.1f}%")
```

### **PASO 10: Guardar Resultados**
```python
print(f"\nPASO 10: Guardar Resultados")
saved_files = save_projection_results(
    df_projected=df_projected,      # Proyecciones finales
    lc_df=lc_df,                   # Curva de luz sintÃ©tica
    mag=mag,                       # Magnitudes limpias
    mag_noisy=mag_noisy,           # Magnitudes con ruido
    survey_params=survey_params,    # Metadatos del survey
    sn_params=sn_params,           # ParÃ¡metros fÃ­sicos SN
    projection_params=projection_params,  # Config tÃ©cnica
    ruido_promedio=ruido_promedio,
    alpha_usado=alpha_usado,
    maximum=maximum
)
```

### **PASO 11: Actualizar Ãndice Maestro**
```python
print(f"\nPASO 11: Actualizar Ãndice Maestro")
create_master_index()  # Actualiza Ã­ndice global de simulaciones
```

---

## ğŸ“Š **RETORNO Y AGREGACIÃ“N**

### **ExtracciÃ³n de EstadÃ­sticas: `extract_run_statistics()`**
```python
def extract_run_statistics(self, iteration_params: Dict) -> Dict:
    # 1. BUSCAR archivo summary mÃ¡s reciente
    search_pattern = f"outputs/**/summary_*{sn_name}*.csv"
    summary_files = glob.glob(search_pattern, recursive=True)
    
    # 2. LEER CSV generado por main.py
    df_summary = pd.read_csv(summary_file)
    row = df_summary.iloc[0]
    
    # 3. EXTRAER mÃ©tricas reales
    return {
        'n_detections': int(row.get('detections', 0)),      # 29
        'n_observations': int(row.get('total_points', 0)),  # 29  
        'detection_rate_percent': float(row.get('detection_rate_percent', 0.0)),  # 100.0
        'ebmv_host': float(row.get('ebmv_host', 0.0)),      # 0.043
        'ebmv_mw': float(row.get('ebmv_mw', 0.0)),          # 0.067
        'status': row.get('status', 'UNKNOWN')              # "SUCCESS"
    }
```

### **AgregaciÃ³n de EstadÃ­sticas: `add_successful_run()`**
```python
def add_successful_run(self, execution_time: float, n_detections: int, 
                      n_observations: int, sn_type: str):
    self.runs_completed += 1
    self.execution_times.append(execution_time)        # Para promedios
    self.total_detections += n_detections              # Suma global
    self.total_observations += n_observations          # Suma global
    
    # EstadÃ­sticas por tipo de SN
    if sn_type not in self.detection_rates_by_type:
        self.detection_rates_by_type[sn_type] = []
    
    detection_rate = n_detections / max(1, n_observations)
    self.detection_rates_by_type[sn_type].append(detection_rate)
```

---

## ğŸ“ **ESTRUCTURA DE OUTPUTS GENERADA**

### **Archivos Individuales (main.py):**
```
outputs/single_runs/run_20250816_143052_SN2006ep/
â”œâ”€â”€ projection_results.csv      â† Detecciones/upper limits por observaciÃ³n
â”œâ”€â”€ metadata.json               â† ParÃ¡metros completos de la simulaciÃ³n
â”œâ”€â”€ lightcurve_plot.png         â† GrÃ¡fico cientÃ­fico curva de luz
â”œâ”€â”€ projection_plot.png         â† GrÃ¡fico temporal de proyecciÃ³n
â””â”€â”€ summary_SN2006ep_Ibc.csv    â† Resumen de 1 fila con mÃ©tricas clave
```

### **Archivos Agregados (batch_runner.py):**
```
outputs/batch_runs/batch_20250816_142830_a1b2c3d4/
â”œâ”€â”€ batch_metadata.json         â† ConfiguraciÃ³n + estadÃ­sticas agregadas
â”œâ”€â”€ run_summary.csv             â† Todas las iteraciones en 1 DataFrame
â”œâ”€â”€ statistical_summary.txt     â† Resumen cientÃ­fico legible
â””â”€â”€ logs/batch_[ID].log         â† Log completo del batch
```

---

## ğŸ”„ **DIAGRAMA DE FLUJO COMPLETO**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CLI INPUTS    â”‚â”€â”€â”€â–¶â”‚ SIMPLE_RUNNER   â”‚â”€â”€â”€â–¶â”‚ SIMPLE_CONFIG   â”‚
â”‚ --runs 50       â”‚    â”‚ parse_arguments â”‚    â”‚ create_simple_  â”‚
â”‚ --filter r      â”‚    â”‚ setup_env       â”‚    â”‚ config()        â”‚
â”‚ --sn-types Ibc  â”‚    â”‚ run_custom_batchâ”‚    â”‚ SimpleConfig    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                        â”‚
                                                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BATCH_RUNNER    â”‚â—€â”€â”€â”€â”‚ run_scientific_ â”‚â—€â”€â”€â”€â”‚ CONFIG OBJECT   â”‚
â”‚ Professional    â”‚    â”‚ batch()         â”‚    â”‚ n_runs=50       â”‚
â”‚ BatchRunner     â”‚    â”‚                 â”‚    â”‚ sn_types=["Ibc"]â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚ filter_band="r" â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PARAMETER       â”‚â”€â”€â”€â–¶â”‚ SINGLE RUN      â”‚â”€â”€â”€â–¶â”‚ MAIN.PY         â”‚
â”‚ GENERATION      â”‚    â”‚ EXECUTION       â”‚    â”‚ PIPELINE        â”‚
â”‚ create_run_     â”‚    â”‚ execute_single_ â”‚    â”‚ main()          â”‚
â”‚ parameters()    â”‚    â”‚ run()           â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                      â”‚                      â”‚
          â–¼                      â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SCIENTIFIC      â”‚    â”‚ CONFIG UPDATE   â”‚    â”‚ 11 PASOS        â”‚
â”‚ SAMPLING        â”‚    â”‚ update_config_  â”‚    â”‚ CIENTÃFICOS     â”‚
â”‚ â€¢ Cosmology     â”‚    â”‚ for_run()       â”‚    â”‚ â€¢ Espectros     â”‚
â”‚ â€¢ Extinction    â”‚    â”‚ â€¢ sn_name       â”‚    â”‚ â€¢ Correcciones  â”‚
â”‚ â€¢ Templates     â”‚    â”‚ â€¢ redshift      â”‚    â”‚ â€¢ FotometrÃ­a    â”‚
â”‚ â€¢ Coordinates   â”‚    â”‚ â€¢ extinctions   â”‚    â”‚ â€¢ ProyecciÃ³n    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                        â”‚
                                                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RESULTS         â”‚â—€â”€â”€â”€â”‚ STATISTICS      â”‚â—€â”€â”€â”€â”‚ OUTPUTS         â”‚
â”‚ AGGREGATION     â”‚    â”‚ EXTRACTION      â”‚    â”‚ â€¢ CSV files     â”‚
â”‚ â€¢ Total detect  â”‚    â”‚ extract_run_    â”‚    â”‚ â€¢ JSON metadata â”‚
â”‚ â€¢ By SN type    â”‚    â”‚ statistics()    â”‚    â”‚ â€¢ Plots         â”‚
â”‚ â€¢ Success rate  â”‚    â”‚                 â”‚    â”‚ â€¢ Logs          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ **FUNCIONES CLAVE POR ARCHIVO**

### **simple_runner.py**
- `main()`: Entry point principal
- `parse_arguments()`: Parseo CLI
- `setup_environment()`: CreaciÃ³n directorios
- `run_custom_batch()`: ConfiguraciÃ³n y ejecuciÃ³n

### **simple_config.py**
- `create_simple_config()`: Factory de configuraciones
- `get_sn_templates()`: Obtener templates por tipo
- `SimpleConfig`: Clase de configuraciÃ³n

### **batch_runner.py**
- `ProfessionalBatchRunner.run_batch()`: Loop principal
- `create_run_parameters()`: Muestreo cientÃ­fico
- `execute_single_run()`: EjecuciÃ³n individual
- `update_config_for_run()`: ActualizaciÃ³n config
- `extract_run_statistics()`: ExtracciÃ³n mÃ©tricas
- `save_batch_results()`: Persistencia agregada

### **main.py**
- `main()`: Pipeline cientÃ­fico 11 pasos
- Funciones de cada paso detalladas arriba

### **core/projection.py**
- `field_projection()`: ProyecciÃ³n temporal core

### **core/correction.py**
- `sample_cosmological_redshift()`: Muestreo cosmolÃ³gico
- `sample_extinction_by_type()`: Distribuciones extinciÃ³n
- `correct_redeening()`: AplicaciÃ³n correcciones

### **core/utils.py**
- `leer_spec()`: Lectura espectros
- `Syntetic_photometry_v2()`: FotometrÃ­a sintÃ©tica
- `Loess_fit()`: Suavizado estadÃ­stico
- `maximo_lc()`: Fecha del mÃ¡ximo

---

## âš ï¸ **PUNTOS CRÃTICOS DOCUMENTADOS**

### **1. Bug de Unidades Temporales (RESUELTO)**
- **Problema**: Fases relativas vs MJD absoluto en proyecciÃ³n
- **SoluciÃ³n**: PASO 7.5 conversiÃ³n explÃ­cita
- **UbicaciÃ³n**: `main.py` lÃ­neas 200-210

### **2. Sistema de Fallback**
- **MÃ©todo primario**: Import directo `main.main()`
- **MÃ©todo fallback**: Subprocess `python main.py`
- **RazÃ³n**: Aislamiento de estado entre iteraciones

### **3. ConfiguraciÃ³n Global**
- **ActualizaciÃ³n**: `update_config_for_run()` modifica `config.py`
- **ValidaciÃ³n**: `load_and_validate_config()` lee valores actualizados
- **Consistencia**: Ambos mÃ©todos (directo/subprocess) ven misma config

### **4. ExtracciÃ³n de EstadÃ­sticas**
- **Fuente**: CSV generado por `save_projection_results()`
- **Timing**: DespuÃ©s de completar `main.main()`
- **ValidaciÃ³n**: Confirma ejecuciÃ³n exitosa vs fallida

---

## ğŸ“ˆ **MÃ‰TRICAS CIENTÃFICAS GENERADAS**

### **Por IteraciÃ³n Individual:**
- `n_detections`: NÃºmero de detecciones
- `n_observations`: Observaciones totales  
- `detection_rate_percent`: Tasa de detecciÃ³n
- `execution_time`: Tiempo de ejecuciÃ³n
- `ebmv_host`, `ebmv_mw`: Extinciones aplicadas

### **Agregadas por Batch:**
- `total_detections`: Suma de todas las detecciones
- `global_detection_rate`: Tasa global
- `detection_rates_by_type`: Distribuciones por tipo SN
- `success_rate`: Tasa de Ã©xito de simulaciones
- `average_execution_time`: Tiempo promedio

### **Distribuciones EstadÃ­sticas:**
- Media, desviaciÃ³n estÃ¡ndar, mediana por tipo SN
- Rangos de redshift, extinciÃ³n, magnitudes
- Cobertura temporal y espacial

---

##  **DISEÃ‘O PARA INVESTIGACIÃ“N **

### **Reproducibilidad CientÃ­fica:**
- Seeds controladas para cada iteraciÃ³n
- Configuraciones completas guardadas
- Trazabilidad end-to-end documentada

### **Escalabilidad:**
- ParalelizaciÃ³n futura posible
- Manejo robusto de errores
- Logging detallado para debugging

### **ValidaciÃ³n AcadÃ©mica:**
- Referencias cientÃ­ficas en distribuciones
- MÃ©todos observacionalmente validados
- EstadÃ­sticas publication-ready

---

**SISTEMA COMPLETO MAPEADO** âœ…  
*DocumentaciÃ³n tÃ©cnica completa para referencia permanente*  
*Actualizado: Agosto 2025*
